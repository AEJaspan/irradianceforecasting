{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 13:32:04.386435: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src import DataPipeline\n",
    "from src import Model\n",
    "from src import IrradianceForecastingModel\n",
    "from src import plot_skill\n",
    "from src import (\n",
    "    normalize_features,\n",
    "    convert_units,\n",
    "    remove_nighttime_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dp = DataPipeline(dev_limit=1000)\n",
    "# dp.load_data()\n",
    "# targets  = [\"dni\", \"ghi\"]\n",
    "# horizons = [\"5min\", \"10min\", \"15min\", \"20min\", \"25min\", \"30min\"]\n",
    "# results=pd.DataFrame()\n",
    "# for t in targets:\n",
    "#     h = horizons[-1]\n",
    "#     target, horizon = t, h\n",
    "#     dp.train_test_split(target, horizon)\n",
    "#     model = Model(dp)\n",
    "#     results = pd.concat([results,model.itterate_through_data()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import particles\n",
    "# from particles import distributions as dists\n",
    "# from particles import state_space_models as ssm\n",
    "# from particles.collectors import Moments\n",
    "# import numpy as np\n",
    "# from sklearn import linear_model\n",
    "\n",
    "# class CustomStateSpaceModel(ssm.StateSpaceModel):\n",
    "#     def PX0(self):\n",
    "#         # Define the distribution of X_0\n",
    "#         return dists.Normal(loc=self.mu, scale=self.sigma / np.sqrt(1. - self.rho**2))\n",
    "    \n",
    "#     def PX(self, t, xp):\n",
    "#         # Define the distribution of X_t given X_{t-1} = xp\n",
    "#         return dists.Normal(loc=self.mu + self.rho * (xp - self.mu), scale=self.sigma)\n",
    "    \n",
    "#     def PY(self, t, xp, x):\n",
    "#         # Define the distribution of Y_t given X_t = x\n",
    "#         return dists.Normal(loc=0., scale=np.exp(x))\n",
    "\n",
    "\n",
    "# def train_particle_filter(Xtra, ytra):\n",
    "#     \"\"\"\n",
    "#     Train the Particle Filter forecasting model.\n",
    "\n",
    "#     Args:\n",
    "#         Xtra (array-like): Exogenous features for training.\n",
    "#         ytra (array-like): Target variable for training.\n",
    "#     Returns:\n",
    "#         None\n",
    "#     \"\"\"\n",
    "#     # Define and create a custom state-space model instance\n",
    "#     mu = -1.0\n",
    "#     rho = 0.9\n",
    "#     sigma = 0.1\n",
    "#     prior_dict = {'mu': mu,\n",
    "#                   'rho' : rho,\n",
    "#                   'sigma' : sigma}\n",
    "#     custom_model = CustomStateSpaceModel(**prior_dict)\n",
    "#     # Create a Bootstrap filter using the custom model and normalized data\n",
    "#     fk_model = ssm.Bootstrap(ssm=custom_model, data=ytra)\n",
    "#     pf = particles.SMC(fk=fk_model, N=1, resampling='stratified',\n",
    "#                             collect=[Moments()], store_history=True)\n",
    "\n",
    "#     # Run the particle filter\n",
    "#     pf.run()\n",
    "#     return pf\n",
    "\n",
    "# def forecast_pf(pf, Xtra):\n",
    "#     # Access estimated states\n",
    "#     estimated_states = pf.hist.X \n",
    "#     # # remove burnin\n",
    "#     # burnin=100\n",
    "#     # for i, param in enumerate(self.prior_dict.keys()):\n",
    "#     #     pf.chain.theta[param][burnin:]\n",
    "#     # Define forecasting horizon\n",
    "#     forecast_horizon = Xtra.shape[0] # 10  # Adjust as needed\n",
    "\n",
    "#     # Initialize arrays to store forecasts\n",
    "#     forecasts = []\n",
    "#     forecast_std_devs = []\n",
    "#     # Generate forecasts for each time step in the forecasting horizon\n",
    "#     for t in range(forecast_horizon):\n",
    "#         # Use the estimated volatility to generate a forecast for the next observation\n",
    "#         # Assuming 'estimated_states' contains the estimated volatilities\n",
    "#         estimated_volatility = estimated_states[t]  # Replace with the appropriate index if needed\n",
    "#         # Generate a forecast for the next observation based on the estimated volatility\n",
    "#         # For example, you can use a normal distribution with mean 0 and standard deviation 'estimated_volatility'\n",
    "#         forecast = np.random.normal(loc=0, scale=np.abs(estimated_volatility))\n",
    "        \n",
    "#         # Append forecast to the forecasts array\n",
    "#         forecasts.append(forecast)\n",
    "        \n",
    "#         # Append the estimated volatility to the forecast_std_devs array for visualization\n",
    "#         forecast_std_devs.append(estimated_volatility)\n",
    "#     return np.array(forecasts).reshape(-1) # , np.array(forecast_std_devs).reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets  = [\"dni\", \"ghi\"]\n",
    "# dp = DataPipeline(dev_limit=1000)\n",
    "# dp.load_data()\n",
    "# horizons = [\"5min\", \"10min\", \"15min\", \"20min\", \"25min\", \"30min\"]\n",
    "# results=pd.DataFrame()\n",
    "# h = horizons[-1]\n",
    "# target, horizon = t, h\n",
    "# train_test_split = dp.train_test_split(target, horizon)\n",
    "\n",
    "# Xtra,Xtes,f = list(train_test_split.itterator)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets  = [\"dni\", \"ghi\"]\n",
    "# horizons = [\"5min\", \"10min\", \"15min\", \"20min\", \"25min\", \"30min\"]\n",
    "\n",
    "# target=targets[0]\n",
    "# t=target\n",
    "# h = horizons[-1]\n",
    "# target, horizon = t, h\n",
    "# dp = DataPipeline(dev_limit=1000)\n",
    "# dp.load_data()\n",
    "# train_test_split = dp.train_test_split(target, horizon)\n",
    "# model = IrradianceForecastingModel()\n",
    "# models = [\n",
    "#             [\"trf\", model.train_transformer, model.forecast_transformer],\n",
    "#             [\"PF\", model.train_particle_filter, model.forecast_pf],\n",
    "#             [\"OLS\", model.train_ols, model.forecast_ols],\n",
    "#         ]\n",
    "# t = targets[1]\n",
    "\n",
    "# name, train_fn, forecast_fn = models[0]\n",
    "# horizons = [\"5min\", \"10min\", \"15min\", \"20min\", \"25min\", \"30min\"]\n",
    "# h = horizons[-1]\n",
    "# target, horizon = t, h\n",
    "# Xtra,Xtes,f = list(train_test_split.itterator)[1]\n",
    "\n",
    "\n",
    "# cols = [\n",
    "#         \"{}_{}\".format(target,horizon),  # actual\n",
    "#         \"{}_kt_{}\".format(target,horizon),  # clear-sky index\n",
    "#         \"{}_clear_{}\".format(target,horizon),  # clear-sky model\n",
    "#         \"elevation_{}\".format(horizon)   # solar elevation \n",
    "#     ]\n",
    "# # Xtra, Xtes = normalize_features(Xtra, Xtes)\n",
    "# m = train_fn(Xtra, dp.train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets  = [sra, dp.train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = train_fn(Xtra, dp.train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_pred = forecast_fn(m, Xtra, dp.train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = forecast_fn(m, Xtra, dp.train_y)\n",
    "test_pred = forecast_fn(m, Xtes, dp.test_y)\n",
    "# convert from kt [-] back to irradiance [W/m^2]\n",
    "convert_units(train_pred, dp.train_clear)\n",
    "convert_units(test_pred, dp.test_clear)\n",
    "# removes nighttime values (solar elevation < 5)\n",
    "remove_nighttime_values(train_pred, dp.train_clear)\n",
    "remove_nighttime_values(test_pred, dp.test_clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dp.test.copy()\n",
    "a['preds'] = test_pred\n",
    "fig = a.plot(backend='plotly')\n",
    "fig.write_html(f\"plots/test_full_model_{name}_{t}_{h}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dp.train.copy()\n",
    "a['preds'] = train_pred\n",
    "fig = a.plot(backend='plotly')\n",
    "fig.write_html(f\"plots/train_full_model_{name}_{t}_{h}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dp.test[cols].copy()\n",
    "a['preds'] = test_pred\n",
    "fig = a.plot(backend='plotly')\n",
    "fig.write_html(f\"plots/{name}_{t}_{h}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
